üç∑ Wine Quality Red ‚Äî Machine Learning

Projeto de Machine Learning para analisar e prever a qualidade de vinhos tintos usando caracter√≠sticas f√≠sico-qu√≠micas.
Inclui etapas de EDA, pr√©-processamento, regress√£o, classifica√ß√£o e AutoML com PyCaret.

üìå Integrantes

Eduardo Rodrigues

Igor Cecim

üéØ Objetivo do Projeto

O projeto tem dois focos principais:

Regress√£o: prever a nota de qualidade (quality) de um vinho tinto.

Classifica√ß√£o: transformar quality em uma classe bin√°ria (‚Äúbom‚Äù vs ‚Äún√£o bom‚Äù) e treinar modelos classificadores.

Al√©m disso, foi feita uma compara√ß√£o entre:

Pipeline manual (scikit-learn)

Pipeline autom√°tico (PyCaret / AutoML)

üßæ Dataset

Arquivo utilizado: winequality-red.csv

Linhas: 1599

Colunas: 12

Separador: ;

Sem valores nulos

Target: quality (nota inteira)

üß† Etapas do Projeto
1. Pr√©-processamento

Padroniza√ß√£o de nomes de colunas.

Remo√ß√£o de duplicatas.

Tratamento de outliers usando IQR (winsoriza√ß√£o/clip).

Normaliza√ß√£o com StandardScaler.

2. EDA (An√°lise Explorat√≥ria)

Estat√≠sticas descritivas (describe, info).

Heatmap de correla√ß√£o.

Pairplot com vari√°veis mais relevantes.

Observa√ß√£o de rela√ß√µes positivas/negativas com quality.

3. Modelos de Regress√£o

Regress√£o Linear (LinearRegression)

Regress√£o Polinomial grau 2 (PolynomialFeatures + LinearRegression)

M√©tricas usadas:

MAE

RMSE

R¬≤

4. Modelos de Classifica√ß√£o

Cria√ß√£o de classe bin√°ria:

good = 1 para vinhos de qualidade alta (ex.: ‚â• 7)

good = 0 caso contr√°rio

Modelos:

Naive Bayes Gaussiano (GaussianNB)

Regress√£o Log√≠stica (LogisticRegression)

Otimiza√ß√£o com GridSearchCV

M√©tricas usadas:

Accuracy

F1-Score

ROC-AUC

Matriz de confus√£o

5. AutoML com PyCaret

compare_models() para benchmark autom√°tico.

tune_model() para otimiza√ß√£o.

Executado tanto para Regress√£o quanto para Classifica√ß√£o.

Principais Resultados (resumo)
Regress√£o

Regress√£o Linear teve desempenho razo√°vel (erro m√©dio ~0.5 ponto).

Regress√£o Polinomial n√£o trouxe ganho significativo.

Classifica√ß√£o

Log√≠stica: maior accuracy geral.

Naive Bayes: melhor F1 (mais sens√≠vel √† classe ‚Äúbom‚Äù).

GridSearch trouxe melhora pequena.

AutoML

PyCaret facilitou a compara√ß√£o de v√°rios modelos e confirma o desempenho pr√≥ximo ao obtido manualmente.

üõ† Tecnologias e Bibliotecas

Python 3.x

Pandas / NumPy

Matplotlib / Seaborn

Scikit-learn

PyCaret

üìå Observa√ß√µes

O dataset √© desbalanceado em notas altas, o que dificulta a predi√ß√£o da classe ‚Äúvinho bom‚Äù.

Resultados podem ter pequenas varia√ß√µes conforme o random_state e splits.
